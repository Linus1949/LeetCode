# 什么是原子性？所谓原子性操作，是指执行行一系列操作时，这些操作要么全部执行，要么全部不执行，不存在只执行其中一部分的情况。# 讲一讲JVM内存模型？与JVM内存结构中的Java堆、栈、方法区等并不是同一个层次的内存划分，无法直接类比。**Java内存模型：**如今的 Java 内存模型下，线程可以把变量保存工作内存（比如机器的寄存器或高速缓存）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成数据的不一致，也就是内存的可见性问题。**JVM内存结构：**包括：Java虚拟机栈，程序计数器，本地方法栈，堆，方法区。程序计数器：用于指示当前线程执行的字节码到第几行了。Java虚拟机栈：描述的是Java方法执行的内存模型，用于存储局部变量，操作数栈，动态链接，方法出口等信息。本地方法栈：存放每个native方法的调用状态。# 什么是悲观锁，什么是乐观锁？悲观锁：它假设数据很容易被其他线程修改，所有它会在处理数据前给数据加个排他锁，上锁成功则操作，否则阻塞。Java种有两种同步互斥的锁机制：synchronized和ReentrantLock。乐观锁：它则认为数据通常不会冲突，在操作前不加排他锁，只有在数据更新前进行检验，若主存数据和修改前一致，则更新，否则滚回。由硬件提供，CAS算法。# 什么是指令重排序？为了提高性能，编译器和处理器通常会对指令进行重排序，重排序指从源代码到指令序列的重排序，分为三种：① 编译器优化的重排序，编译器在不改变单线程程序语义的前提下可以重排语句的执行顺序。② 指令级并行的重排序，如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。③ 内存系统的重排序。# 谈一谈synchronized每个Java对象都有一个关联的monitor（监听器），使用synchronized 就是拿到对象的monitor（JVM帮助获取）进行加解锁的判断。如果成功加锁就成为该monito的唯一持有者，monitor在被释放前不能再被其他线程获取。同步代码块使用 monitorenter 和 monitorexit 这两个字节码指令获取和释放 monitor（相当于wait和notify）。这两个字节码指令都需要一个引用类型的参数指明要锁定和解锁的对象，对于同步普通方法，锁是当前实例对象；对于静态同步方法，锁是当前类的Class对象；对于同步方法块，锁是synchronized括号里的对象。执行 monitorenter 指令时，首先尝试获取对象锁。如果这个对象没有被锁定，或当前线程已经持有锁，就把锁的计数器加 1，执行 monitorexit 指令时会将锁计数器减 1。一旦计数器为 0 锁随即就被释放。例如有两个线程 A、B 竞争 monitor，当 A 竞争到锁时会将 monitor 中的 owner 设置为 A，把 B 阻塞并放到等待资源的 ContentionList 队列。ContentionList 中的部分线程会进入 EntryList，EntryList 中的线程会被指定为 OnDeck 竞争候选者，如果获得了锁资源将进入 Owner 状态，释放锁后进入 !Owner 状态。被阻塞的线程会进入 WaitSet。被 synchronized 修饰的同步块对一条线程来说是可重入的，并且同步块在持有锁的线程释放锁前会阻塞其他线程进入。从执行成本的角度看，持有锁是一个重量级的操作。Java 线程是映射到操作系统的内核线程上的，如果要阻塞或唤醒一条线程，需要操作系统帮忙完成，不可避免用户态到核心态的转换。_**不公平的原因**_所有收到锁请求的线程首先自旋，如果通过自旋也没有获取锁将被放入ContentionList，该做法对于已经进入队列的线程不公平。为了防止ContentionList尾部的元素被大量线程进行CAS访问影响性能，Owner线程会在释放锁时将ContentionList的部分线程移动到EntryList并指定某个线程为OnDeck线程，该行为叫做竞争切换，牺牲了公平性但提高了性能。# 悲观锁（synchronized）和volatile有什么区别？_**在内存可见性问题上：**_synchronized修饰的代码块执行时会先清除工作内存内的资源，直接从主存获得最新资源，并将运算结果保存在工作内存，在退出时更新主存，保证了内存的可见性。volatile修饰的代码块也是直接从主存获取资源，但是运算结果不会经过工作内存，而是直接刷新在主存上，并且对于修饰了volatile的资源，其他线程会遵循缓存一致性协议，直接去获取最新资源，从而解决了可见性。_**在原子性方面：**_synchronized相当于给这段代码块上了个锁，其他线程无法对被锁上的资源进行操作，被判定为阻塞态，从而引起上下文切换，这是一种强同步，具有原子性。而volatile则没有这个过程。所以总的来说：虽然他们都能一定程度解决内存可见性问题，但是由于synchronized会引起上下文切换，所以开销上会大不少，降低了并发性。而volatile则是弱同步，他修饰的代码块不具有原子性。_**在有序性方面：**_代码在执行的过程中的先后顺序，Java 在编译器以及运行期间的优化，代码的执行顺序未必就是编写代码时候的顺序。volatile关键字设置内存屏障而保证有序(禁止重排优化)， 而synchronized是通过保证只有一个线程在操作从而保证有序性。所以总结来说，两者在读取数据的时候是一样的，都会清空缓存读取最新主存。但是写入时不一样，volatile是直接刷新主存，而synchronized会多一个缓存流程。（_**缓存一致性协议：**_每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器要对这个数据进行修改操作的时候，会强制重新从系统内存里把数据读到处理器缓存里。所以，如果一个变量被volatile所修饰的话，在每次数据变化之后，其值都会被强制刷入主存。而其他处理器的缓存由于遵守了缓存一致性协议，也会把这个变量的值从主存加载到自己的缓存中。这就保证了一个volatile在并发编程中，其值在多个缓存中是可见的。）# 什么是伪共享，怎么造成的，如何避免？cpu访问变量时，如果工作内存（cpu cache）中有变量，则会直接从中获得而不用访问主存。否则就会去主存获得变量，然后把该变量所在区域的一个cache行大小的内存复制到cache中（局部性原理），然而我们只需要是一个变量，但是cache行复制进来了多个变量，这样就会导致其他线程所需的变量被锁，从而造成性能下降，这就是伪共享。JDK8之前一般都是通过字节填充的方式来避免的。就是创建一个变量时用填充字段填充该变量的缓存行，这样就避免了多个变量放在同一个缓存行里了(空间换时间)。# 公平锁与非公平锁（ReentrantLock实现）：公平锁表示线程早请求早锁，非公平锁则是按线程调度算法来，若没有公平需求，一般都是非公平锁，因为公平锁会引发额外的线程调度。# 独占锁与共享锁：独占锁就是上了个排他锁，只允许一个进程访问资源。例如synchronized和ReentrantLock。而共享锁允许多个线程访问资源。例如读操作不回影响数据的一致性，用独占锁就降低了线程的并发性。例如ReadWriteLock。这两种锁java并发包都提供，都是基于AQS实现的，AQS就是分为独占和共享模式。# 乐观锁：CAS是如何实现非阻塞同步的？有啊，CAS（Compare and Swap）算法，由硬件提供，是JDK提供的非阻塞原子性操作。一句话解释：线程执行后要更新主存前先验证一下，当前的主存值是否和刚进来时一样，不一样就说明其他线程用过了，我在脏读应该滚回。一样就说明没问题，我这次操作是原子的。有个缺点，会引发ABA环形转换问题，比如线程1接受了旧预期值A，在执行CAS时，切换线程了，然后线程2进来，把这个A值改成B，然后又改成A，这时线程1用到的那个A就和真正的A虽然值一样，但是实际上不是一个东西了。JDK中的AtomicStampedReference 类给每个变量的状态.都配备了一个时间戳， 从而避免了ABA 问题的产生，好像用的不太多，使用传统互斥锁更高效。# Wait()和notifyAll()，notify()?在Java中，可以通过配合调用 Object 对象的 wait() 方法和 notify()方法或 notifyAll() 方法来实现线程间的通信。在线程中调用 wait() 方法，将阻塞等待其他线程的通知（其他线程调用 notify() 方法或 notifyAll() 方法），在线程中调用 notify() 方法或 notifyAll() 方法，将通知其他线程从 wait() 方法处返回。Object 是所有类的超类，它有 5 个方法组成了等待/通知机制的核心：notify()、notifyAll()、wait()、wait(long)和wait(long，int)。在Java中，所有的类都从Object继承而来，因此，所有的类都拥有这些共有方法可供使用。而且，由于他们都被声明为 final，因此在子类中不能覆写任何一个方法。这里详细说明一下各个方法在使用中需要注意的几点。_**wait()**_public final void wait() throws InterruptedException,IllegalMonitorStateException该方法用来将当前线程置入休眠状态，直到接到通知或被中断为止。在调用 wait()之前，线程必须要获得该对象的对象级别锁，即只能在同步方法或同步块中调用 wait()方法。进入 wait()方法后，当前线程释放锁。在从 wait()返回前，线程与其他线程竞争重新获得锁。如果调用 wait()时，没有持有适当的锁，则抛出 IllegalMonitorStateException，它是 RuntimeException 的一个子类，因此，不需要 try-catch 结构。_**notify()**_public final native void notify() throws IllegalMonitorStateException该方法也要在同步方法或同步块中调用，即在调用前，线程也必须要获得该对象的对象级别锁，的如果调用 notify()时没有持有适当的锁，也会抛出 IllegalMonitorStateException。该方法用来通知那些可能等待该对象的对象锁的其他线程。如果有多个线程等待，则线程规划器任意挑选出其中一个 wait()状态的线程来发出通知，并使它等待获取该对象的对象锁（notify 后，当前线程不会马上释放该对象锁，wait 所在的线程并不能马上获取该对象锁，要等到程序退出 synchronized 代码块后，当前线程才会释放锁，wait所在的线程也才可以获取该对象锁），但不惊动其他同样在等待被该对象notify的线程们。当第一个获得了该对象锁的 wait 线程运行完毕以后，它会释放掉该对象锁，此时如果该对象没有再次使用 notify 语句，则即便该对象已经空闲，其他 wait 状态等待的线程由于没有得到该对象的通知，会继续阻塞在 wait 状态，直到这个对象发出一个 notify 或 notifyAll。这里需要注意：它们等待的是被 notify 或 notifyAll，而不是锁。这与下面的 notifyAll()方法执行后的情况不同。_**notifyAll()**_public final native void notifyAll() throws IllegalMonitorStateException该方法与 notify ()方法的工作方式相同，重要的一点差异是：notifyAll 使所有原来在该对象上 wait 的线程统统退出 wait 的状态（即全部被唤醒，不再等待 notify 或 notifyAll，但由于此时还没有获取到该对象锁，因此还不能继续往下执行），变成等待获取该对象上的锁，一旦该对象锁被释放（notifyAll 线程退出调用了 notifyAll 的 synchronized 代码块的时候），他们就会去竞争。如果其中一个线程获得了该对象锁，它就会继续往下执行，在它退出 synchronized 代码块，释放锁后，其他的已经被唤醒的线程将会继续竞争获取该锁，一直进行下去，直到所有被唤醒的线程都执行完毕。_**深入理解**_如果线程调用了对象的 wait()方法，那么线程便会处于该对象的等待池中，等待池中的线程不会去竞争该对象的锁。当有线程调用了对象的 notifyAll()方法（唤醒所有 wait 线程）或 notify()方法（只随机唤醒一个 wait 线程），被唤醒的的线程便会进入该对象的锁池中，锁池中的线程会去竞争该对象锁。优先级高的线程竞争到对象锁的概率大，假若某线程没有竞争到该对象锁，它还会留在锁池中，唯有线程再次调用 wait()方法，它才会重新回到等待池中。而竞争到对象锁的线程则继续往下执行，直到执行完了 synchronized 代码块，它会释放掉该对象锁，这时锁池中的线程会继续竞争该对象锁。# java中如何让一个线程等待另一个线程执行完后再执行？该问题大概有3种方法：1.notify、wait方法，Java中的唤醒与等待方法，关键为synchronized代码块，也常用Object作为参数。2.用join方法，在主线程中调用其他线程的join方法。原理就是主线程会不断确认被调用的其他线程是否存活，如果存活，那么让当前线程一直wait，直到thread线程终止，线程的this.notifyAll 就会被调用，继续执行主线程。3.countdownlatch和cycleBarrier，原理就是将对象的state值设置为N，只有当需要提前执行的线程执行完或执行到理想的点，触发N-1，直到state为0，才会继续执行主线程。# 线程有哪些方法？① sleep 方法导致当前线程进入休眠状态，与 wait不同的是该方法不会释放锁资源，进入的是 TIMED-WAITING 状态。② yiled 方法使当前线程让出 CPU 时间片给优先级相同或更高的线程，回到 RUNNABLE 状态，与其他线程一起重新竞争CPU时间片。③ join 方法用于等待其他线程运行终止，如果当前线程调用了另一个线程的 join 方法，则当前线程进入阻塞状态，当另一个线程结束时当前线程才能从阻塞状态转为就绪态，等待获取CPU时间片。底层使用的是wait，也会释放锁。# Java中线程间通讯有哪些方式？_**Volatile：**_告知程序任何对变量的读需要从主内存中获取，写必须同步刷新回主内存，保证所有线程对变量访问的可见性。_**Synchronized：**_确保多个线程在同一时刻只能有一个处于方法或同步块中，保证线程对变量访问的原子性、可见性和有序性。_**等待通知机制：**_指一个线程A调用了对象的wait方法进入等待状态，另一线程B调用了对象的notify/notifyAll 方法，线程A收到通知后结束阻塞并执行后序操作。对象上的wait和notify/notifyAll如同开关信号，完成等待方和通知方的交互。如果一个线程执行了某个线程的join方法，这个线程就会阻塞等待执行了join方法的线程终止，这里涉及等待/通知机制。join底层通过wait实现，线程终止时会调用自身的notifyAll方法，通知所有等待在该线程对象上的线程。_**管道 IO 流：**_用于线程间数据传输，媒介为内存。PipedOutputStream和PipedWriter是输出流，相当于生产者，PipedInputStream和PipedReader是输入流，相当于消费者。管道流使用一个默认大小为1KB 的循环缓冲数组。输入流从缓冲数组读数据，输出流往缓冲数组中写数据。当数组已满时，输出流所在线程阻塞；当数组首次为空时，输入流所在线程阻塞。_**ThreadLocal：**_是线程共享变量，但它可以为每个线程创建单独的副本，副本值是线程私有的，互相之间不影响。阻塞队列有哪些选择?阻塞队列支持阻塞插入和移除，当队列满时，阻塞插入元素的线程直到队列不满。当队列为空时，获取元素的线程会被阻塞直到队列非空。阻塞队列常用于生产者和消费者的场景，阻塞队列就是生产者用来存放元素，消费者用来获取元素的容器。# ThreadLocal可以用来干嘛，与同步机制有什么不同？**ThreadLocal能够实现“数据隔离”，获取当前线程的局部变量值，不受其他线程影响。**解决的就是让每个线程绑定自己的值。如果你创建了一个ThreadLocal变量，那么访问这个变量的每个线程都会复制变量到自己工作内存中。他们可以使用get（）和set（）方法来获取默认值或将其值更改为当前线程所存的副本的值，从而可以避免线程安全问题。同步机制采用了“以时间换空间”的方式，而ThreadLocal采用了“以空间换时间”的方式。前者仅提供一份变量，让不同的线程排队访问，而后者为每一个线程都提供了一份变量，因此可以同时访问而互不影响。# ThreadLocal的实现原理：每个Thread线程类都有threadLocals和inheritableThreadLocals变量（这俩是ThreadLocalMap，特殊的Map），默认情况下是null。只有当前线程调用ThreadLocal类的set和get时，才会进行创建。每个线程的本地变量就放在这个threadLocals里面。set方法把本地变量值保存在当前线程的threadLocals里，get则从threadLocals里取出来。不需要本地变量时应该用remove方法把本地变量移除，不然会一直存放在里面占用线程的工作内存。由于每个线程可以关联多个Thread变量，所以他才设计成Map，**其中key是当前线程的实例引用，value是复制过来的本地变量值**。这样我们就实现了将ThreadLocal变量保存在每个线程中。# ThreadLocal的缺点_**内存泄漏：**_虚线为弱引用。一般来说，线程结束会自动清除ThreadLocal，但是我们一般使用的是线程池，所以线程不会结束，所以ThreadLocal不会清除，会产生null，value的键值对，这样就造成了内存泄漏。使用完ThreadLocal方法后最好手动调remove()方法。_**不支持继承：**_由于父线程和子线程是两个不同的线程，因此子线程无法通过get返回父线程的ThreadLocal变量值。但是也有解决办法，那就是inheritableThreadLocals。它的原理就是在父线程创建子线程时，通过Thread构造函数将父线程的inheritableThreadLocals传递进来，将其复制到自己线程的inheritableThreadLocals里，这样就成功继承了。以后操作的时候用InheritableThreadLocals类来创建ThreadLocal就能够得到继承功能。# 为什么要使用线程池，如何使用？_**降低资源消耗：**_通过重复利用已创建的线程降低线程创建和销毁造成的消耗。_**提高响应速度：**_当任务到达时，任务可以不需要的等到线程创建就能立即执行。_**提高线程的可管理性：**_线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。_**使用方法：**_先创建一个线程池executors = new  ThreadPoolExecutor(核心线程数, 线程池数量, 等待时间, 单位, 队列, 饱和策略)，然后以Runable或者其他形式定义worker线程，每定义一个线程启动executors.execute提交此线程，最后shutdown中止。_**原理：**_核心就是execute方法，传参后，进行以下判断。（任务队列是核心线程后面一小截，用来缓存的）如果当前线程量小于核心数量——>加入新建核心线程并执行。如果当前线程量大于核心数量且线程池在执行——>尝试CAS操作将线程加入任务队列，这里再进行二次running检测，若当前线程为0，则创建非核心线程入队**（这个阶段其实就是一边进一边出）**。非以上情况，要么说明队列满了，要么线程池没有在执行线程——>创建非核心线程入队（60s不用会自动清除）。任何非核心进程入队失败（当前线程数大于线程池数量）——>都会执行饱和策略。# 如何确定线程池大小？线程池太少，会导致线程池创建线程频繁，消耗cpu，甚至可能导致任务队列太长，内存溢出。但是太大，会导致线程上下文切换频繁，增加线程执行时间，影响实际效率，因此最佳值可能要根据实际运行情况进行调优。一般来说参考这两个公式：_**CPU 密集型任务(N+1)：**_这种任务消耗的主要是 CPU 资源，可以将线程数设置为 N（CPU 核心数）+1，比 CPU 核心数多出来的一个线程是为了**防止线程偶发的缺页中断，或者其它原因导致的任务暂停而带来的影响**。一旦任务暂停，CPU 就会处于空闲状态，而在这种情况下多出来的一个线程就可以充分利用 CPU 的空闲时间。_**I/O 密集型任务(2N)：**_这种任务应用起来，系统会用大部分的时间来处理 I/O 交互，而线程在处理 I/O 的时间段内不会占用 CPU 来处理，这时就可以将 CPU 交出给其它线程使用。因此在 I/O 密集型任务的应用中，我们可以多配置一些线程，具体的计算方法是 2N。# 谈一谈AQS原理：AQS 就是个实现线程同步用到的队列。如果线程请求的资源空闲，则将让此线程操作这个资源并将资源上锁。否则，就将该线程封装成Node放入这个AQS双向队列，等下次轮到他的时候再尝试执行。其中State变量用来表示代表当前锁的状态，0代表没有被占用，大于 0 代表有线程持有当前锁（可大于1，用于重入，如果锁住资源的线程是现在想抢资源的线程，那直接进来，State+1就行了，退出时-1，最多退到0）exclusiveOwnerThread指向锁住资源的线程。这个waitState变量用volatile修饰来保证可见性，并用CAS算法来进行原子修改。# WaitState=-1的含义是下一个节点需要被唤醒synchronized关键字可用来修饰方法和代码块。实际上是对一个类的对象进行上锁，先取得对象的监视器（java中每个对象里都有这个），当这个计数器变成0说明可以上锁，否则说明被占用。进入synchronized代码块是会上锁，退出时会解锁，在内部，通过wait和notify方法操控线程的走走停停，wait使得线程挂起并释放资源，notifty唤醒下一个请求此资源被阻塞的线程（notiftyAll则是唤醒所有请求此资源的线程）。类似于生产者消费者机制。# 新版本对synchronized的优化有哪些？_**自旋锁：**_其他线程被调度发现锁被占用后会进入阻塞态挂起，在后续被调度时才会被唤醒，这两部都深入操作系统内核，十分占据开销。自旋锁通过自选一段时间多次确认能否获得锁，来尽量避免这种情况。_**锁消除：**_锁消除主要是通过逃逸分析来支持，如果堆上的共享数据不可能逃逸出去被其它线程访问到，那么就可以把它们当成私有数据对待，也就可以将它们的锁进行消除。（比如String操作内就有很多隐式锁）锁粗化：对于同一个对象频繁上下锁也会引起性能损耗，可以锁粗化，锁一次就行了。最后一个优化是锁的分配和膨胀策略。# 锁的分配和膨胀原理：_**前情提要：**_Mark Word中记录了锁的种类和指向的线程栈。_**建锁初期：**_资源是无锁状态，Mark Word也是无锁标记。_**当只有一个线程来竞争锁时：**_我们给资源打上偏向锁，记录该线程ID表示是熟人，下次又遇到它来可以直接让他执行（也就是现在还没必要指向CAS操作）。_**当有偏向线程外的线程来竞争锁时:**_这时升级为轻量级锁，公平竞争先来先得，交替执行，比起偏向锁多执行一个CAS环节，用来判断是否引发同步问题。_**当出现更多线程来竞争资源:**_此时轻量级锁有可能会升级为重量级锁。用CAS替换Mark Word的信息执行失败时，说明有其他线程刚刚在操作此资源，我们检验Mark Word指向的线程栈。若资源的Mark Word的指针不是当前线程，说明有其他现在正在操作此资源，互斥了，进行自旋，若还是无法获得锁，则要进行升级。否则，说明CAS替换成功，自己获得了当前资源（无竞争了），没必要升级，维持轻量级锁状态，继续进入同步块。同理，在释放的时候，CAS替换Mark Word成功，说明表示无竞争直接释放**（还是轻量级锁）**。否则说明有竞争**（升级成重量级了）**，要在释放后唤醒被挂起的线程。**轻量级锁解决的是：减少无实际竞争情况下，重锁带来内核开销。****偏向锁解决的是：减少无竞争且只有一个线程时，所带来的轻量级锁来带的开销。**# AQS如何实现ReentrantLock？_**上锁流程如下：**_对于公平锁而言，我们执行lock方法，内部会进入acquire方法调用tryAcquire，试一下抢锁（这是公平锁的语义，没人抢我就不进阻塞队列了）。如果state=0，那么我们根据先来后到执行（用CAS判断，因为我们要公平锁）。如果重入了，则state+1。如果是其他情况，说明获取失败false，自旋的将线程封装成Node加入并置为AQS队列尾端（这里还要执行次CAS保证同步）。挂机流程：由于当前节点的唤醒依靠的是前节点，所以在入队时，要循环验证前节点的状态：若前节点是head的同时自己抢做成功了，则直接将当前节点置为head执行（这里看到了，入队方法也包含了重置head，决定谁使用cpu的过程）。否则，若是-1则直接挂起并返回ture，若是>0,则说明前节点被启动了，当前节点的prev指针得一直前挪找个好爹，若=0，将其状态置为-1，其余情况都是false。从上面来看，只有前节点的状态为-1时直接挂起入队成功，其他情况均会进入循环直到抢锁成功或找到-1的前节点而成功入队。**_解锁流程如下**：_进入release方法内执行tryRelease，试着解锁，state-=1，若减完后为0，说明没有重入锁了，该释放了，执行unparkSuccessor唤醒下一个节点（这里输入的时head（代表当前线程），也就是释放head节点的下一个节点）。唤醒流程：先将head的状态置0，表示资源空闲，如果head的下一个节点是null或者其状态>0,则从后往前寻找最靠近head的下一个就绪节点（因为后续节点可能提前抢到了锁）并将其唤醒。线程唤醒后，当前线程就可以挂起了。**总结：**1.锁状态。我们要知道锁是不是被别的线程占有了，这个就是 state 的作用，它为 0 的时候代表没有线程占有锁，可以去争抢这个锁，用 CAS 将 state 设为 1，如果 CAS 成功，说明抢到了锁，这样其他线程就抢不到了，如果锁重入的话，state进行 +1 就可以，解锁就是减 1，直到 state 又变为 0，代表释放锁，所以 lock() 和 unlock() 必须要配对啊。然后唤醒等待队列中的第一个线程，让其来占有锁。2.线程的阻塞和解除阻塞。AQS 中采用了 LockSupport.park(thread) 来挂起线程，用 unpark 来唤醒线程。3.阻塞队列。因为争抢锁的线程可能很多，但是只能有一个线程拿到锁，其他的线程都必须等待，这个时候就需要一个 queue 来管理这些线程，AQS 用的是一个 FIFO 的队列，就是一个链表，每个 node 都持有后继节点的引用。# 信号量是什么原理？_**原理：**_synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。原理和独占模式是一样的，只不过是多增加了个阈值来限制当前资源能够共享的最大线程量，这个阈值就是state。有几个线程就把state变量设置为几。每进来一个线程，判断state：state <= 0，自旋或挂起进去AQS队列，否则，调用acquire方法state对应资源的state-1。release方法时释放锁，state+1，并唤醒AQS阻塞的线程。_**应用：**_他只能用于读问题，用于写的话会造成线程不安全。_**规律：**_多个线程同时读一个资源类的时候是没有任何问题，所以为了满足并发量，读取共享资源应该同时进行。 但是，如果有一个线程想去写共享资源，就不应该有其他线程去读或者写# countdownLatch是什么原理？_**作用：**_让一组子线程先执行，在他们执行完之前主线程不能动。_**原理：**_CountDownLatch让N个子线程阻塞在同一个地方，默认构造 AQS 的 state 值为N。每执行一个子线程用countDownLatch. down方法CAS的减少state，直至state为0就代表所有的子线程都执行完了（修正：不一定是执行完，你的countDownLatch. down方法可以设置在子线程任何地方）。调用countDownLatch.await方法（main线程会被park），如果state不为0，就代表仍然有子线程没有执行完，那么就把已经执行完的线程都放入阻塞队列，并自旋判断state = 0，直至最后一个线程调用了countDown，使得state = 0（main线程会被unpark）。于是阻塞的线程便判断成功，继续往下执行主线程。_**应用：**_1.某一线程在开始运行前等待n个线程执行完毕。将CountDownLatch 的计数器初始化为n ，当计数器的值变为 0 时，在CountDownLatch.await()上的线程就会被唤醒。一个典型应用场景就是启动一个服务时，主线程需要等待多个组件加载完毕，之后再继续执行。2.实现多个线程开始执行任务的最大并行性。类似于赛跑，将多个线程放到起点，等待发令枪响，然后同时开跑。做法是初始化一个共享的CountDownLatch对象，将其计数器初始化为 1，多个线程在开始执行任务前首先countdownlatch.await()，当主线程调用countDown()时，计数器变为0，多个线程同时被唤醒。_**缺点：**_CountDownLatch是一次性的，计数器的值只能在构造方法中初始化一次，之后没有任何机制再次对其设置值，当CountDownLatch使用完毕后，它不能再次被使用。# CycleBarrier是什么，原理呢？_**作用：**_让一组（N个）线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。_**原理：**_CyclicBarrier内部通过一个count变量作为计数器，count的初始值为自定义的线程数量屏障值（parties），每当一个线程到了栅栏这里了（执行到cb.await方法这），计数器减一。如果 count 值为 0 了，表示这是这一组最后一个线程，就尝试执行我们构造方法中输入的任务。（从源码看，这里在执行构造任务后，会唤醒所有被拦截的线程，所以出现N个线程线finish，第N+1个才ready的情况）_**应用：**_可用于多线程计算数据。例如一个excel保存了所有用户一年的银行流水，我们可以设置栅栏多线程处理每个账户的日均流水，处理完后通过构造任务一次性计算整个Excel的日均流水。# 两者区别_**CountDownLatch:**_一个或者多个线程，等待其他多个线程完成某件事情之后才能执行。_**CyclicBarrier:**_多个线程互相等待，直到到达同一个同步点，再继续一起执行。1.前者是一次性的，后者可以反复使用设置。2.对于CountDownLatch来说，重点是“一个线程（多个线程）等待”，而其他的 N 个线程在完成“某件事情”之后，可以终止，也可以等待。而对于CyclicBarrier，重点是多个线程，在任意一个线程没有完成，所有的线程都必须等待。CountDownLatch是计数器，线程完成一个记录一个，只不过计数不是递增而是递减，而CyclicBarrier更像是一个阀门，需要所有线程都到达，阀门才能打开，然后继续执行。# 谈一谈共享锁和独占锁的应用场景和底层区别**在作用场合方面**：独占锁是一种悲观锁，一般用于写操作频繁场景，因为写操作严格要求资源同步，若在这里运用共享锁，则会避免读写冲突，产生数据不一致的情况。共享锁是一种乐观锁，可用于读操作频繁场所，因为读操作之间不会影响数据的一致性，若在这里运用独占锁，则会造成读线程阻塞，这是不必要的开销。**在原理实现层面**：独占锁的话，对于同一个资源，若是发生竞争，则容易导致线程阻塞和唤醒。共享锁的话，只要不是超过规定阈值或者被栅栏屏障堵塞，发生竞争通过CAS自旋就能够快速获得锁，阻塞频率一般不会有独占锁高。结合：Java的并发包中提供了ReadWriteLock，读-写锁。它允许一个资源可以被多个读操作访问，或者被一个写操作访问，但两者不能同时进行。