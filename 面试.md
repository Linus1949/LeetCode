后台开发

1. Java 线程的状态都有哪些？
   线程通常都有五种状态

   - 创建： 使用 new 操作符创建一个新线程时，此时它有了相应的内存空间和其它资源，但是还没有开始执行
   - 就绪： 当线程启动时，线程进入就绪状态，由于还没有分配 CPU，线程将进入线程队列排队
   - 运行： 就绪状态的线程被调用并获得处理器资源时，线程就进入了运行状态
   - 阻塞： 被人为挂起或需要执行耗时的输入输出操作时，将让出 CPU 并暂时终止；阻塞被消除后是回到就绪状态
   - 死亡： 调用 stop(), destory()或 run()方法执行结束后

2. wait 和 sleep 的区别
   wait 和 sleep
   - wait 和 sleep 的主要区别是调用 wait 方法时，线程在等待的时候会释放掉它所获得的 monitor，但是调用 Thread.sleep()方法时，线程在等待的时候仍然会持有 monitor 或者锁。另外，Java 中的 wait 方法应在同步代码中调用，但是 sleep 方法不需要。
   1. wait()方法将会让当前线程进入条件队列等待，并且释放锁。 这点和 Thread.sleep 不一样，Thread.sleep 会让线程睡眠，但是不释放锁。

需要注意的是 wait()方法的退出条件是它被 notify 或者 notifyAll 方法唤醒了，并且在又一次的锁竞争中获得了锁，也就说，当 wait 方法退出时，当前线程还是持有锁的。

    2. notify()

    3. notifyAll()方法，唤醒条件队列中所有的等待线程，让它们参与锁竞争

3. wait 和 notify 的使用场景
   wait()和 notify()在 Java 中实现线程通信，用于多个线程
   如生产者与消费者模式，当容器为空时，消费者调用 wait()，每当消费完成就会 notify()其它线程

4. 介绍一下 volatile 以及原理
   在 Java 多线程中，我们需要维护可见性，有序性和原子性。在 JMM 中，当线程需要某个资源时需要先从主内存拷贝到工作内存，在没有 volatile 修饰时，被线程更改过的数据是不会被及时更新到主内存，也就是说在新的数据更新前如果有其它线程拷贝了主内存上的旧值就无法保证线程之间的可见性。volatile 可以帮助在线程工作内存上更新的数据可以及时更新到主内存上，并且将别的线程上的参数进行无效标注

5. 介绍一下 synchornized 以及原理
   在 Java 中，关键字 Synchronized 可以保证在同一时刻，只有一个线程可以执行某个方法或者某个代码块(主要是对方法或者代码块中存在共享数据的操作)，同时我们还应该注意到 synchronized 的另一个重要作用，synchronized 可保证一个线程的变换(主要是对共享数据的变化)被其他线程所看到(保证可见性，完全可以替代 volatile 功能)。

   Synchronized 的三种应用方式

   1. 修饰实例方法，作用于当前实例加锁，进入同步代码前要获得当前实例的锁
   2. 修饰静态方法，作用于当前类对象加锁，进入同步代码前要获得当前类对象的锁
   3. 修饰代码块，指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁

   synchronized 底层语义原理
   Java 虚拟机中的同步(synchronization)基于进入和退出管程(monitor)对象实现，无论是显式同步(有明确的 monitorenter 和 monitorexit 指令，即同步代码块)还是隐式同步都是如此。在 Java 语言中，同步用的最多的地方可能是被 synchronized 修饰的同步方法。同步方法 并不是由 monitorenter 和 monitorexit 指令来实现同步的，而是由方法调用指令读取运行时常量池中方法的 ACC_SYNCHRONIZED 标志来隐式实现的。

   其中轻量级锁和偏向锁是 Java 6 对 synchronized 锁进行优化后新增加的，稍后我们会简要分析。这里我们主要分析一下重量级锁也就是通常说 synchronized 的对象锁，锁标识位为 10，其中指针指向的是 monitor 对象（也称为管程或监视器锁）的起始地址。每个对象都存在着一个 monitor 与之关联，对象与其 monitor 之间的关系有存在多种实现方式，如 monitor 可以与对象一起创建销毁或当线程试图获取对象锁时自动生成，但当一个 monitor 被某个线程持有后，它便处于锁定状态。在 Java 虚拟机(HotSpot)中，monitor 是由 ObjectMonitor 实现的，其主要数据结构如下（位于 HotSpot 虚拟机源码 ObjectMonitor.hpp 文件，C++实现的）

   ObjectMonitor 中有两个队列，\_WaitSet 和 \_EntryList，用来保存 ObjectWaiter 对象列表( 每个等待锁的线程都会被封装成 ObjectWaiter 对象)，\_owner 指向持有 ObjectMonitor 对象的线程，当多个线程同时访问一段同步代码时，首先会进入 \_EntryList 集合，当线程获取到对象的 monitor 后进入 \_Owner 区域并把 monitor 中的 owner 变量设置为当前线程，同时 monitor 中的计数器 count 加 1，若线程调用 wait() 方法，将释放当前持有的 monitor，owner 变量恢复为 null，count 自减 1，同时该线程进入 WaitSet 集合中等待被唤醒。若当前线程执行完毕也将释放 monitor(锁)并复位变量的值，以便其他线程进入获取 monitor(锁)。

1)  锁的种类：自旋锁，自旋锁的其他种类，阻塞锁，可重入锁，读写锁，互斥锁，悲观锁，乐观锁，公平锁
    1.1 可重入锁：如果锁具备可重入性，则称作为可重入锁。synchronized 和 ReentrantLock 都是可重入锁，可重入性在我看来实际上表明了锁的分配机制：基于线程的分配，而不是基于方法调用的分配。举比如说，当一个线程执行到 method1 的 synchronized 方法时，而在 method1 中
    调用另外一个 synchronized 方法 method2，此时该线程不必重新去申请锁，而是可以直接执行方法 method2
    1.2 读写锁：读写锁将对一个资源的访问分成了 2 个锁，一个读锁和一个写锁。正因为有了读写锁，才使得多个线程之间的读操作不会发生冲突。ReadWriteLock 就是读写锁，它是一个接口，ReentrantReadWriteLock 实现了这个接口。可以通过 readLock()获取读锁，通过 writeLock()获取写锁。
    1.3 可中断锁：可中断锁，即可以中断的锁。在 Java 中，synchronized 就不是可中断锁，而 Lock 是可中断锁。
    如果某一线程 A 正在执行锁中的代码，另一线程 B 正在等待获取该锁，可能由于等待时间过长，线程 B 不想等待了，想先处理其他事情，我们可以让它中断自己或者在别的线程中中断它，这种就是可中断锁。 Lock 接口的 lockInterruptibly()方法体现了 Lock 的可中断性
    1.4 公平锁: 公平锁即尽量以请求锁的顺序来获取锁。同时有多个线程在等待一个锁，当这个锁被释放时，等待时间越久的那个线程（最先请求的
    线程）会获得锁。
    非公平锁即无法保证锁的获取是按照请求锁的顺序进行的，这就可能导致某个或者某些线程永远获取不到锁。
    Synchronized 是非公平锁，无法保证等待的线程获取锁的顺序。对于 ReentreantLock 和 ReentrantReadWriteLock 默认都是非公平锁，但可以设置为公平锁

2)  Lock 的使用
    Lock：用来获取锁，如果锁被其他线程获取，处于等待状态。如果采用 Lock，必须去主动去释放锁，并且在异常发生时，不会自动释放锁。因此一般来说，使用 Lock 必须在 try{}catch{}块中进行，并且将释放的锁的操作放在 finally 块中进行，保证锁一定会释放，防止死锁的发生。

    lockInterruptibly:通过这个办法去获取锁时，如果线程正在等待获取锁，则这个线程能响应中断，即中断线程的等待状态。

    tryLock: tryLock 方法时又返回值的，他表示用来尝试获取锁，如果获取成功，则返回 true，如果获取失败(即锁已被其他线程获取)，则返回 false，也就是说这个方法无论如何都会立刻返回。在拿不到锁时不会一直等待。

    tryLock(long, TimeUnit)：与 tryLock 类似，不过是加了等待时间，在等待时间内获取到锁都会返回 true，超时返回 false。

    unlock：释放锁，一定要在 finally 块中释放

3)  reentrantLock：实现了 Lock 接口，可重入锁，内部定义了公平锁与非公平锁。默认为非公平锁：
    public ReentrantLock(){
    syn = fair ? new FairSync() : new NonfairSync();
    }
4)  ReadWriteLock:
    public interface ReadWriteLock{
    Lock readLock();
    Lock writeLock();
    }
    一个用来获取读锁，一个用来获取写锁。也就是说将文件的读写操作分开，分成两个锁来分配给线程，从而使得多个线程可以同时进行读写操作。ReentrantReadWriteLock 实现了 ReadWriteLock 接口，并为实现 Lock 接口。
    注意：1. 如果有一个线程已经占用了读锁，则此时其他线程如果要申请写锁，则申请写锁的线程会一直等待释放读锁。 2. 如果有一个线程已经占用了写锁，则此时其他线程如果要申请写锁或者读锁，则申请的线程会一直等待释放写锁。

5)  synchronized 和 lock 的区别：
    . Lock 是接口，而 synchronized 是 Java 中的关键字，synchronized 是内置的语言实现；
    . synchronized 在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而 Lock 在发生异常时，如果没有主动通过 unlock()去释放锁，则很可能发生死锁，因此使用 Lock 时需要在 finally 块中释放；
    . Lock 可以让等待锁的线程中断，而 synchronized 则不行，等待的线程会一直等待下去，不能够响应中断；
    . 通过 Lock 可以知道有没有成功获取到锁，而 synchronized 却办不到；
    . Lock 可以提高多个线程进行读写的操作（通过 readWriteLock 实现读写分离）
    . 性能上来说，在资源竞争不激烈的情形下，Lock 性能稍微比 synchronized 差点（编译程序会尽可能的优化 synchronized）。但是当同步非常激烈的时候，synchronized 的性能一下子能下降好几十倍。而 ReentrantLock 却还能维持常态。

Final 关键字：
  1、final 修饰类：当用 final 修饰一个类时，表明这个类不能被继承。 也就是说，如果一个类你永远不会让他被继承，就可以用 final 进行修饰。final 类中的成员变量可以根据需要设为 final，但是要注意 final 类中的所有成员方法都会被隐式地指定为 final 方法。
   在使用 final 修饰类的时候，要注意谨慎选择，除非这个类真的在以后不会用来继承或者出于安全的考虑，尽量不要将类设计为 final 类。
  2、final 修饰方法：“使用 final 方法的原因有两个。第一个原因是把方法锁定，以防任何继承类修改它的含义；第二个原因是效率。在早期的 Java 实现版本中，会将 final 方法转为内嵌调用。但是如果方法过于庞大，可能看不到内嵌调用带来的任何性能提升。在最近的 Java 版本中，不需要使用 final 方法进行这些优化了。”
   因此，如果只有在想明确禁止该方法在子类中被覆盖的情况下才将方法设置为 final 的。注：类的 private 方法会隐式地被指定为 final 方法。
  3、final 修饰变量：对于一个 final 变量，如果是基本数据类型的变量，则其数值一旦在初始化之后便不能更改；如果是引用类型的变量，则在对其初始化之后便不能再让其指向另一个对象。
   当 final 变量是基本数据类型以及 String 类型时，如果在编译期间能知道它的确切值，则编译器会把它当做编译期常量使用。也就是说在用到该 final 变量的地方，相当于直接访问的这个常量，不需要在运行时确定。

    关键字final的好处小结
      1、final关键字提高了性能。JVM和Java应用都会缓存final变量。
      2、final变量可以安全的在多线程环境下进行共享，而不需要额外的同步开销。
      3、使用final关键字，JVM会对方法、变量及类进行优化。
      4、对于不可变类，它的对象是只读的，可以在多线程环境下安全的共享，不用额外的同步开。

Static 关键字：
static 关键字的用途
  《Java 编程思想》：“static 方法就是没有 this 的方法。在 static 方法内部不能调用非静态方法，反过来是可以的。而且可以在没有创建任何对象的前提下，仅仅通过类本身来调用 static 方法。这实际上正是 static 方法的主要用途。”
   这段话虽然只是说明了 static 方法的特殊之处，但是可以看出 static 关键字的基本作用，简而言之，一句话来描述就是：
   方便在没有创建对象的情况下来进行调用（方法/变量）。
   很显然，被 static 关键字修饰的方法或者变量不需要依赖于对象来进行访问，只要类被加载了，就可以通过类名去进行访问。
  static 可以用来修饰类的成员方法、类的成员变量，另外可以编写 static 代码块来优化程序性能。
  1）、static 方法
  static 方法一般称作静态方法，由于静态方法不依赖于任何对象就可以进行访问，因此对于静态方法来说，是没有 this 的，因为它不依附于任何对象，既然都没有对象，就谈不上 this 了。并且由于这个特性，在静态方法中不能访问类的非静态成员变量和非静态成员方法，因为非静态成员方法/变量都是必须依赖具体的对象才能够被调用。
   但是要注意的是，虽然在静态方法中不能访问非静态成员方法和非静态成员变量，但是在非静态成员方法中是可以访问静态成员方法/变量的。
   因此，如果说想在不创建对象的情况下调用某个方法，就可以将这个方法设置为 static。我们最常见的 static 方法就是 main 方法，至于为什么 main 方法必须是 static 的，现在就很清楚了。因为程序在执行 main 方法的时候没有创建任何对象，因此只有通过类名来访问。
  2）、static 变量
  static 变量也称作静态变量，静态变量和非静态变量的区别是：静态变量被所有的对象所共享，在内存中只有一个副本，它当且仅当在类初次加载时会被初始化。而非静态变量是对象所拥有的，在创建对象的时候被初始化，存在多个副本，各个对象拥有的副本互不影响。
  static 成员变量的初始化顺序按照定义的顺序进行初始化。
  3）、static 代码块
  static 关键字还有一个比较关键的作用就是用来形成静态代码块以优化程序性能。static 块可以置于类中的任何地方，类中可以有多个 static 块。在类初次被加载的时候，会按照 static 块的顺序来执行每个 static 块，并且只会执行一次。
   为什么说 static 块可以用来优化程序性能，是因为它的特性:只会在类加载的时候执行一次。因此，很多时候会将一些只需要进行一次的初始化操作都放在 static 代码块中进行。

    static关键字的误区：
      1）、static关键字会改变类中成员的访问权限吗？
      Java中的static关键字不会影响到变量或者方法的作用域。在Java中能够影响到访问权限的只有private、public、protected（包括包访问权限）这几个关键字。
      2）、能通过this访问静态成员变量吗？
      虽然对于静态方法来说没有this，那么在非静态方法中能够通过this访问静态成员变量吗？主要考察this和static的理解。在这里永远要记住一点：静态成员变量虽然独立于对象，但是不代表不可以通过对象去访问，所有的静态方法和静态变量都可以通过对象访问（只要访问权限足够）。
      3）、static能作用于局部变量么？
      在Java中切记：static是不允许用来修饰局部变量，这是Java语法的规定。
      4）、java中是否可以覆盖（override）一个private方法或者static方法？
      都不能
      覆盖，也就是我们常说的重写，是子类继承父类，且子类中的方法和父类中的方法，方法名相同，参数个数和类型相同，返回值相同。
      private修饰的方法，不能被继承，所以也不存在重写（覆盖）
      static修饰的方法，是静态方法，在编译时就和类名就行了绑定。而重写发生在运行时，动态绑定的。 何况static方法，跟类的实例都不相关，所以概念上也适用。
      5）、静态导包
      Static还有一种不太常用的用法，即静态导包用法，将类的方法直接导入到当前类中，从而直接使用“方法名”即可调用类方法，更加方便。

Java 基础之 ConcurrentHashMap

    1. HashMap线程不安全：因为多线程的情况下，使用HashMap进行put操作可能会引起死循环，导致CPU利用率接近100%，所以在并发情况下不能使用HashMap
    2. HashTable线程安全但效底下：HashTable容器使用synchronized来保证线程安全，但在线程竞争激烈的情况下HashTable的效率非常低下。因为当一个线程访问HashTable的同步方法时，其他线程访问HashTab的同步方法，可能会进入阻塞或轮训状态。比如线程1使用put添加元素，线程2不但不能使用put方法添加，也不能使用get方法获取元素，所以竞争越激烈效率越低。

    3. 解决：
    		-分段锁：HashTable之所以在竞争激烈的环境下性能差，是因为所有访问HashTable的线程都必须竞争同一把锁，如果容器有多把锁，每把锁用于锁容器容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时就不会发生锁竞争，从而有效提高并发访问效率。ConcurrentHashMap是由Segment数组结构和HashEntry数组结构完成的。Segment是一种可重入锁ReentrantyLock，在ConcurrentHashMap里扮演锁的角色，HashEntry则用于存储件键值对数据，一个ConcurrentHashMap里包含一个Segment数组，Segment的结构和HashMap类似，是一种数组和链表结构， 一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素，每个Segment守护者一个HashEntry数组里的元素,当对HashEntry数组的数据进行修改时，必须首先获得它对应的Segment锁。


    		-JDK1.8的实现已经完全抛弃了Segment分段锁机制，利用CAS+Synchronized来保证并发更新的安全。数据结构采用：数组+链表+红黑树。ConcurrentHashMap是发散列映射表，他允许完全并发的读取，并且支持给定数量的并发更新。ConcurrentHashMap 是设计为非阻塞的。在更新时会局部锁住某部分数据，但不会把整个表都锁住。同步读取操作则是完全非阻塞的。好处是在保证合理的同步前提下，效率很高。坏处是严格来说读取操作不能保证反映最近的更新。例如线程A调用putAll写入大量数据，期间线程B调用get，则只能get到目前为止已经顺利插入的部分数据。

HashMap 扩容机制 1. 存放新值的时候当前已有元素的个数必须大于等于阈值 2. 存放新值的时候当前存放数据发生 hash 碰撞（当前 key 计算的 hash 值换算出来的数组下标位置已经存在值） 3. void resize(int newCapacity) {
　　　　 Entry[] oldTable = table;
　　　　 int oldCapacity = oldTable.length;
　　　　//判断是否有超出扩容的最大值，如果达到最大值则不进行扩容操作
　　　　 if (oldCapacity == MAXIMUM_CAPACITY) {
　　　　　　 threshold = Integer.MAX_VALUE;
　　　　　　 return;
　　　　}

Entry[] newTable = new Entry[newCapacity];
　　　　// transfer()方法把原数组中的值放到新数组中
　　　　 transfer(newTable, initHashSeedAsNeeded(newCapacity));
　　　　//设置 hashmap 扩容后为新的数组引用
　　　　 table = newTable;
　　　　//设置 hashmap 扩容新的阈值
　　　　 threshold = (int)Math.min(newCapacity \* loadFactor, MAXIMUM_CAPACITY + 1);
　　}

CAS 介绍：（compare and Swap）CAS 有三个操作数，内存值 V，旧的预期值 A，要修改的新值 B.当且仅当预期值 A 和内存值 V 相同时，将内存 V 修改为 B，否则什么都不做。CAS 有效地说明了“我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。”通常将 CAS 用于同步的方式是从地址 V 读取值 A，执行多步计算来获得新 值 B，然后使用 CAS 将 V 的值从 A 改为 B。如果 V 处的值尚未同时更改，则 CAS 操作成功。

CAS 存在的问题：
1.ABA 问题。因为 CAS 需要在操作值的时候检查下它的值有没有发生变化，如果没有发生变化则更新，如果一个值原来是 A，变成了 B，又变成了 A，那么使用 CAS 进行检查时会发现它的值没有发生变化，但是实际上却发生了。ABA 问题的解决思路就是使用版本号。在变量前追加版本号，每次变量更新的时候把版本号加一，那么 A-B-A 就会变成 1A-2B-3A.

    	2.循环时间长开销大。自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令，使用CPU不会消耗过多的执行资源，延迟时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出的时候因内存顺序冲突而引起的CPU流水线被清空，从而提升CPU的执行效率。

    	3. 只能保证一个共享变量的原子操作。当对一个共享变量操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁。

我们知道 ArrayList 是线程不安全的，并发正常修改导致一个人正在写入，另一个同学来抢夺，导致数据不一致，并发修改异常。解决方法就是使用 CopyOnWriteArrayList，CopyOnWrite 容器即写时复制，往容器中添加一个元素时，不直接往当前容器 Object[]添加，而是先将当前容器 Object[]进行 copy，复制出一个新的容器 Object[] newElements, 让新的容器添加元素，添加完之后，再将原容器的引用指向新的容器 setArray(new Elements)，这样做可以对 CopyOnWrite 容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素，所以 CopyOnWrite 容器也是一种读写分离的思想，读和写不同的容器。

线程安全实现自增：1. 使用 Java 提供的原子类：
public static AtomicInteger atomicInteger = new AtomicInteger(0); 2. 使用 Synchronized 同步方法:
public synchornized int increment();
使用 volatile 不能解决非原子操作的线程问题，因为++i，实际包含三个独立的操作：1.读取 count 的值，2.将值加 1，3.将计算结果写入 count，并且其结果状态依赖于之前的状态。

Java 并发编程：线程池的使用 1. 为什么要使用线程池？ - 创建线程和销毁线程开销是比较大的，这些时间有可能比处理业务的时间还要长。这样频繁的创建和销毁线程，再加上业务工作线程，消耗系统资源的时间，可能导致系统资源不足。（我们可把创建和销毁线程的过程去掉）

    	2. 线程池有什么作用？
    	- 提高效率。创建好一定数量的线程放在池中，等需要使用的时候就从池中拿出一个，这要比需要的时候创建一个线程对象快得多。
    	- 方便管理。可以编写线程池管理代码对池中的线程统一进行管理，比如启动时该程序创建了100个线程，每当有请求时，就分配一个去工作，如果刚好并发有101个请求，那么多的这个请求可以排队等候，避免因无休止的创建线程导致系统崩溃。

    	说说常见的线程池及使用场景
    	1. newSingleThreadExecutor: 创建一个单线程化的线程池，他只会用唯一的工作线程来执行任务，保证所有人物按照指定顺序(FIFO, LIFO, 优先级)执行。
    	public static ExecutorService newSingleThreadExecutor(){
    		return new FinalizableDelegatedExecutorService
    		(new ThreadPoolExecutor(1, 1,
    								0L,  TimeUnit.MILLISECONDS,
    								new LinkedBlockingQueue<Runnable>()));
    	}

    	2. newFixedThreadPool: 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。
    	public static ExecutorService newCachedThreadPool(int nThreads){
    		return new ThreadPoolExecutor(nThreads, nThreads,
    									  0L, TimeUnit.MILLIISECONDS,
    									  new LinkedBlockingQueue<Runnable>());
    	}

    	3. newCachedThreadPool: 创建一个可缓存的线程池，如果线程池长度超过处理需求，可灵活回收空闲线程，若无可回收，则新建线程。
    	public static ExecutoreService newCachedThreadPool(){
    		return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
    									  60L, TimeUnit.SECONDS,
    									  new SynchrononusQueue<Runnable>());
    	}
    	4. newScheduledThreadPool：创建一个定长线程池，支持定 时及周期性任务执行。
    	public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize){
    		return new ScheduledThreadPoolExecutor(corePoolSize);
    	}

    	线程池不允许使用Executor去创建，而是通过ThreadPoolExecutor的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。说明：Executors更个方法的弊端：
    		1） newFixedThreadPool和newSingleThreadExecutor：
    			主要问题是堆积的请求处理队列可能会耗费非常大的内存，甚至OOM。
    		2） newCachedThreadPool和newScheduledThreadPool：
    			主要问题是线程数最大数是Integer.MAX_VALUE，可能会创建数量非常多的线程，甚至OOM。

    	corePoolSize：线程池的基本大小，即在没有任务需要执行的时候线程池的大小，并且只有在工作队列满了的情况下才会创建超出这个数量的线程。这里需要注意的是：在刚刚创建ThreadPoolExecutor的时候，线程并不会立即启动，而是要等到有任务提交时才会启动，除非调用了prestartCoreThread/prestartAllCoreThreads事先启动核心线程。再考虑到keepAliveTime和allowCoreThreadTimeOut超时参数的影响，所以没有任务需要执行的时候，线程池的大小不一定是corePoolSize。

    	maximumPoolSize：线程池中允许的最大线程数，线程池中的当前线程数目不会超过该值。如果队列中任务已满，并且当前线程个数小于maximumPoolSize，那么会创建新的线程来执行任务。这里值得一提的是largestPoolSize，该变量记录了线程池在整个生命周期中曾经出现的最大线程个数。为什么说是曾经呢？因为线程池创建之后，可以调用setMaximumPoolSize()改变运行的最大线程的数目。

    	PoolSize：线程池中当前线程的数量，当该值为0的时候，意味着没有任何线程，线程池会终止；同一时刻，poolSize不会超过maximumPoolSize。

    	线程池都有哪几种工作队列：
    	1. ArrayBlockingQueue: 是一个基于数组结构的有界阻塞队列，此队列按 FIFO（先进先出）原则对元素进行排序。
    	2. LinkedBlockingQueue: 一个基于链表结构的阻塞队列，此队列按FIFO （先进先出） 排序元素，吞吐量通常要高于ArrayBlockingQueue。静态工厂方法Executors.newFixedThreadPool()使用了这个队列。
    	3. SynchronousQueue: 一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQueue，静态工厂方法Executors.newCachedThreadPool使用了这个队列。
    	4。 PriorityBlockingQueue：一个具有优先级的无限阻塞队列。

饿汉式：
好处：由于使用了 static 关键字，保证了在引用这个变量时，关于这个变量的所以写入操作都完成，所以保证了 JVM 层面的线程安全。
坏处：不能实现懒加载，造成空间浪费，如果一个类比较大，我们在初始化的时就加载了这个类，但是我们长时间没有使用这个类，这就导致了内存空间的浪费。
public class SingletonObj {
//利用静态变量来储存唯一实例
private static final SingletonObj instance = new SingletonObj();
//私有化构造函数
private SingletonObj(){

    	}
    	//提供公开获取实例接口
    	public static SingletonObj getInstance(){
    		return instance;
    	}
    }

懒汉式：
好处：实现了懒加载，节约了内存空间
坏处：1.在不加锁的情况下，线程不安全，可能出现多份实例 2.在加锁的情况下，会是程序串行化，使系统有严重的性能问题
public class SingletonObj{
private static SingletonObj instance;
private SingletonObj(){

    	}
    	public sychornized static SingletonObj getInstance(){
    		if(instance==null){
    			instance = new SingletonObj();
    		}
    		return instance;
    	}
    }
    虽然使用synchronized解决多份实例的问题，但并发下会使得系统的性能大大下降。


    1.单例模式DCL代码(Double Check Lock双端检锁机制)在加锁前和加锁后都进行一次判断
    public static SingletonDemo getInstance(){
    	//第一次判断，如果这里不为空，不进入抢锁阶段，直接返回实例
        if(instance==null){
            synchronized(SingletonDemo.class){
            	//强锁之后再判断是否为空
                if(instance==null){
                    instance = new SingletonDemo();
                }
            }
        }
        return instance;
    }
    双重检查锁模式是一种非常好的单例实现模式，解决了单例、性能、线程安全问题，上面的双重检测锁模式看上去完美无缺，其实是存在问题，在多线程的情况下，可能会出现空指针问题，出现问题的原因是JVM在实例化对象的时候会进行优化和指令重排序操作。什么是指令重排？，看下面这个例子，简单了解一下指令从排序。
    大部分运行结果构造函数只会被执行一次，但指令重排机制会让程序又很小的几率出现构造函数方法被多次执行。
    DCL(双端检锁)机制不一定线程安全，原因是有指令重排的存在，加入volatile可以禁止指令重排。
        memory = allocate(); //1.分配对象内存空间
        instance(memory);   //2.初始化对象
        instance = memory;  //设置instance执行刚分配的内存地址，此时instance!=NULL
    步骤2和步骤3不存在数据依赖关系，而且无论重排前还是重排后程序的执行结果在单线程中并没有改变，因此这种重排优化是允许的，如果3步骤提前于步骤2，但是instance还没有初始化完成, 但是指令重排只会保证串行语义的执行的一致性（单线程），但并不关心多线程间的语义一致性。所以当一条线程访问instance不为null时，由于instance示例未必已初始化完成，也就造成了线程安全问题。
    为了解决以上问题我们可以将SingletonDemo实例加上volatile
    	//添加volatile关键字
    	private static volatile SingletonDemo instance;

    	private SingletonDemo(){

    	}

    	public static SingletonDemo getInstance(){
    		if(instance==null){
    			sychornized(SingletonDemo.class){
    				if(instance==null){
    					instance = new SingletonDemo();
    				}
    			}
    		return instance;
    		}
    	}

    静态内部类单例模式：静态内部类单例模式也称单例持有者模式，实例由内部类创建，由于 JVM 在加载外部类的过程中, 是不会加载静态内部类的, 只有内部类的属性/方法被调用时才会被加载, 并初始化其静态属性。静态属性由static修饰，保证只被实例化一次，并且严格保证实例化顺序。静态内部类单例模式代码如下：
    	public class SingletonDemo{
    		private SingletonDemoe(){

    		}
    		//单例持有者
    		private static class InstanceHolder{
    			private final static SingletonDemo instance = new SingletonDemo();
    		}
    		//
    		public static SingletonDemo getInstance(){
    			//调用内部类属性
    			return InstanceHolder.instance;
    		}
    	}

    枚举类型实现单例模式：枚举类实现单例模式是 effective java 作者极力推荐的单例实现模式，因为枚举类型是线程安全的，并且只会装载一次，设计者充分的利用了枚举的这个特性来实现单例模式，枚举的写法非常简单，而且枚举类型是所用单例实现中唯一一种不会被破坏的单例实现模式。

    public class SingletonObj{
    	private SingletonObj(){

    	}
    	//枚举类型是线程安全的，并且只会装载一次
    	private enum Singleton{
    		INSTANCE;
    		private final SingletonObj instance;

    		Singleton(){
    			instance = new Singleton();
    		}

    		private SingletonObj getInstance(){
    			return instance();
    		}
    	}
    	public static SingletonObj getInstance(){
    		return Singleton.INSTANCE.getInstance();
    	}
    }

一致性 hash： 1. 使用 Hash 的问题：
上述的方式虽然提升了性能，我们不再需要对整个 Redis 服务器进行遍历！但是，使用上述 Hash 算法进行缓存时，会出现一些缺陷，主要体现在服务器数量变动的时候，所有缓存的位置都要发生改变！

    	试想一下，如果4台缓存服务器已经不能满足我们的缓存需求，那么我们应该怎么做呢？很简单，多增加几台缓存服务器不就行了！假设：我们增加了一台缓存服务器，那么缓存服务器的数量就由4台变成了5台。那么原本hash(a.png) % 4 = 2 的公式就变成了hash(a.png) % 5 = ？ ， 可想而知这个结果肯定不是2的，这种情况带来的结果就是当服务器数量变动时，所有缓存的位置都要发生改变！换句话说，当服务器数量发生改变时，所有缓存在一定时间内是失效的，当应用无法从缓存中获取数据时，则会向后端数据库请求数据（还记得上一篇的《缓存雪崩》吗？）！

    	同样的，假设4台缓存中突然有一台缓存服务器出现了故障，无法进行缓存，那么我们则需要将故障机器移除，但是如果移除了一台缓存服务器，那么缓存服务器数量从4台变为3台，也是会出现上述的问题！

    	所以，我们应该想办法不让这种情况发生，但是由于上述Hash算法本身的缘故，使用取模法进行缓存时，这种情况是无法避免的，为了解决这些问题，Hash一致性算法（一致性Hash算法）诞生了！

    	2. 一致性Hash算法也是使用取模的方法，只是，刚才描述的取模法是对服务器的数量进行取模，而一致性Hash算法是对2^32取模，什么意思呢？简单来说，一致性Hash算法将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0-2^32-1（即哈希值是一个32位无符号整形），整个空间按顺时针方向组织，圆环的正上方的点代表0，0点右侧的第一个点代表1，以此类推，2、3、4、5、6……直到2^32-1，也就是说0点左侧的第一个点代表2^32-1， 0和2^32-1在零点中方向重合，我们把这个由2^32个点组成的圆环称为Hash环。
    	下一步将各个服务器使用Hash进行一个哈希，具体可以选择服务器的IP或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置，这里假设将上文中四台服务器使用IP地址哈希后在环空间。接下来使用如下算法定位数据访问到相应服务器：将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器！

    	3. 一致性Hash算法的容错性和可扩展性
    	现假设Node C不幸宕机，可以看到此时对象A、B、D不会受到影响，只有C对象被重定位到Node D。一般的，在一致性Hash算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。此时对象Object A、B、D不受影响，只有对象C需要重定位到新的Node X ！一般的，在一致性Hash算法中，如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它数据也不会受到影响。
    	综上所述，一致性Hash算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。

    	4. Hash环的数据倾斜问题
    	一致性Hash算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜（被缓存的对象大部分集中缓存在某一台服务器上）问题，例如系统中只有两台服务器。此时必然造成大量数据集中到Node A上，而只有极少量会定位到Node B上。为了解决这种数据倾斜问题，一致性Hash算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器IP或主机名的后面增加编号来实现。例如上面的情况，可以为每台服务器计算三个虚拟节点，于是可以分别计算 “Node A#1”、“Node A#2”、“Node A#3”、“Node B#1”、“Node B#2”、“Node B#3”的哈希值，于是形成六个虚拟节点。同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到“Node A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上。这样就解决了服务节点少时数据倾斜的问题。在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。

主从分布延迟怎么办： 1. 主从复制的原理： 1.数据库有个 bin-log 二进制文件，记录了所有 sql 语句。 2.我们的目标就是把主数据库的 bin-log 文件的 sql 语句复制过来。 3.让其在从数据的 relay-log 重做日志文件中再执行一次这些 sql 语句即可。 4.下面的主从配置就是围绕这个原理配置 5.具体需要三个线程来操作：
binlog 输出线程。每当有从库连接到主库的时候，主库都会创建一个线程然后发送 binlog 内容到从库。
在从库里，当复制开始的时候，从库就会创建两个线程进行处理：
从库 I/O 线程。当 START SLAVE 语句在从库开始执行之后，从库创建一个 I/O 线程，该线程连接到主库并请求主库发送 binlog 里面的更新记录到从库上。从库 I/O 线程读取主库的 binlog 输出线程发送的更新并拷贝这些更新到本地文件，其中包括 relay log 文件。
从库的 SQL 线程。从库创建一个 SQL 线程，这个线程读取从库 I/O 线程写到 relay log 的更新事件并执行。

    			步骤一：主库db的更新事件(update、insert、delete)被写到binlog
    			步骤二：从库发起连接，连接到主库
    			步骤三：此时主库创建一个binlog dump thread，把binlog的内容发送到从库
    			步骤四：从库启动之后，创建一个I/O线程，读取主库传过来的binlog内容并写入到relay log
    			步骤五：还会创建一个SQL线程，从relay log里面读取内容，从Exec_Master_Log_Pos位置开始执行读取到的更新事件，将更新内容写入到slave的db（技术文）

HTTP/1HTTP/2HTTP/3：
HTTP1.1 与 HTTP2
HTTP1.1 的缺陷：1. 高延迟-队头阻塞(Head-Of-Line-Blocking) 2. 无状态特性-阻碍交互 3. 明文传输-不安全性 4. 不支持服务端推送

    			对头阻塞：是指当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也会被一并阻塞，会导致客户端迟迟收不到数据。
    			针对队头阻塞：1. 将同一页面的资源分散到不同的域名下，提升连接上限。虽然公用一个TCP通道，但是在一个管道中同一时刻只能处理一个请求，在当前的请求没有结束之前，其他的请求只能处于阻塞状态。
    						2. 减少请求数量
    						3. 内联一些资源：CSS base64 图片等
    						4. 合并小文件减少资源数

    			无状态特性：是指协议对连接状态没有记忆能力。纯净的HTTP是没有Cookie等机制等，每一个连接都是一个新的连接。上一次请求验证了用户名和密码，而下一次请求服务器并不知道它与上一次请求有何关联，换句话说就是掉登陆态。

    			不安全性：传输内容没有加密，中途可能被篡改和劫持。

    			SPYD协议：SPDY 是由 google 推行的改进版本的 HTTP1.1 (那时候还没有 HTTP2)。

    					|------|
    					| HTTP |
    					|______|
    					|      |
    					| SPDY |
    					|------|
    					|  SSL |
    					|------|
    					|  TCP |
    					|______|
    			特性：1. 多路复用-解决队头阻塞
    			     2. 头部压缩-解决巨大的HTTP头部
                     3. 请求优先级-先获取重要数据
                     4. 服务端推送-填补空缺
                     5. 提高安全性

                多路复用：SPDY 允许在一个连接上无限制并发流。因为请求在一个通道上，TCP 效率更高（参考 TCP 拥塞控制 中的慢启动）。更少的网络连接，发出更密集的包。

                头部压缩：使用专门的 HPACK 算法，每次请求和响应只发送差异头部，一般可以达到 50%~90% 的高压缩率。

                请求优先级：虽然无限的并发流解决了队头阻塞的问题，但如果带宽受限，客户端可能会因防止堵塞通道而阻止请求。在网络通道被非关键资源堵塞时，高优先级的请求会被优先处理。

                服务端推送：可以让服务端主动把资源文件推送给客户端。当然客户端也有权利选择是否接收。

                提高安全性：支持使用 HTTPS 进行加密传输。


                HTTP2：HTTP2 基于 SPDY，专注于性能，最大的一个目标是在用户和网站间只用一个连接。

                新增特性：1. 二进制分帧-HTTP2性能增强的核心
                		 2. 多路复用-解决串行的文件传输和连接数过多

                二进制分帧：首先，HTTP2 没有改变 HTTP1 的语义，只是在应用层使用二进制分帧方式传输。因此，也引入了新的通信单位：帧、消息、流。
                分帧有什么好处？服务器单位时间接收到的请求数变多，可以提高并发数。最重要的是，为多路复用提供了底层支持。

                多路复用：一个域名对应一个连接，一个流代表了一个完整的请求-响应过程。帧是最小的数据单位，每个帧会标识出该帧属于哪个流，流也就是多个帧组成的数据流。多路复用，就是在一个 TCP 连接中可以存在多个流。

                HTTP2的缺陷：1. TCP以及TCP+TLS建立连接的延时
                			2. TCP的队头阻塞并没有彻底解决
                			3. 多路复用导致服务器压力上升
                			4. 多路复用容易TimeOut

                建连延时：TCP 连接需要和服务器进行三次握手，即消耗完 1.5 个 RTT 之后才能进行数据传输。TLS 连接有两个版本—— TLS1.2 和 TLS1.3，每个版本建立连接所花的时间不同，大致需要 1~2 个 RTT。

                RTT（Round-Trip Time）:往返时延。表示从发送端发送数据开始，到发送端收到来自接收端的确认（接收端收到数据后便立即发送确认），总共经历的时延。

                队头阻塞没有彻底解决：TCP为了保证可靠传输，有一个“超时重传”机制，丢失的包必须等待重传确认。HTTP2 出现丢包时，整个 TCP 都要等待重传，那么就会阻塞该 TCP 连接中的所有请求。

                多路复用导致服务器压力上升：多路复用没有限制同时请求数。请求的平均数量与往常相同，但实际会有许多请求的短暂爆发，导致瞬时 QPS 暴增。

                多路复用容易 Timeout：大批量的请求同时发送，由于 HTTP2 连接内存在多个并行的流，而网络带宽和服务器资源有限，每个流的资源会被稀释，虽然它们开始时间相差更短，但却都可能超时。即使是使用 Nginx 这样的负载均衡器，想正确进行节流也可能很棘手。 其次，就算你向应用程序引入或调整排队机制，但一次能处理的连接也是有限的。如果对请求进行排队，还要注意在响应超时后丢弃请求，以避免浪费不必要的资源

1. 计算机网络体系结构
   1.1 简介： 定义 计算机网络的各层+其协议的集合
   作用 定义该计算机网络的所能完成的功能
   1.2 结构介绍：计算机网络体系结构分为三种：OSI 体系结构，TCP/IP 体系结构，五层体系结构
   OSI 体系结构：概念清楚 & 理念完整，但复杂 & 不实用
   TCP / IP 体系结构：含了一系列构成互联网基础的网络协议，是 Internet 的核心协议 &被广泛应用于局域网 和 广域网
   五层体系结构：融合了 OSI 与 TCP / IP 的体系结构，目的是为了学习 & 讲解计算机原理
   低三层为通信子网，负责数据传输 高三层为资源子网，相当于计算机系统，完成数据处理； 传输层承上启下

   OSI： 1.网络接口层：负责与链路（传输媒介）的数据传输工作；传输单位：帧；组帧，差错控制 ，流量控制和传输管理；接口标准：EIA-232C，CCITT 的 X.21 2.网络层：为不同的主机提供通讯服务：网路层的分组数据从源端传到目的端；数据报；封装数据成组/包，路由选择；IP 协议：提供网络节点之间的报文传送服务；ARP 协议：实现 IP 地址向物理地址的映射；RARP 协议：实现物理地址向 IP 地址的映射；ICMP 协议：探测&报告传输中产生的错误；IGMP 协议：管理多播组测成员关系；其余：IPX，OSPF 3.传输层：为不同主机中的进程间提供通信服务；报文段(TCP)，用户数据报(UDP)，为端到端的连接提供可靠的传输服务，为端到端的连接提供流量控制，差错控制，数据传输管理服务；TCP 协议：提供用户间面向连接，可靠的报文传输服务。UDP 协议：提供用户间无连接，不可靠的报文传输服务。 4.应用层：为特性类型的网络应用提供访问 OSI 环境手段；HTTP 协议：提供 Internet 网络浏览服务；DNS 协议：负责域名和 IP 地址的映射；SMTP 协议：提供简单的电子邮件发送服务；POP 协议：提供对邮箱服务器进行远程存取的服务，与此功能类似的还有 IMAP 协议；FTP 协议：提供应用级文件传输服务；SMB 协议：提供应用级文件共享传输服务；Telnet 协议：提供远程登录服务(明文传输)；SSH 协议：提供远程登录协议(加密)。

TCP 协议：Transmission Control Protocol，传输控制协议，属于传输层通信协议，基于 TCP 的应用层协议有 HTTP，SMTP，FTP，POP3

UDP 协议：User Datagram Protocol，用户数据报协议，属于传输层通信协议，基于 UDP 的应用层协议有 TFTP，SNMP 和 DNS

特点：无连接 -> 使用 UDP 传输数据前，不需要建立 UDP 连接
不可靠 -> UDP 的数据包发送后，不管其是否会到达接收方(会出现丢保现象)
面向报文 -> 数据以数据报文(包)的形式传输 (UDP 数据报文没有长度限制，都是一次发送，不像 TC 票会拆分)
无拥塞控制 -> 由于是不可靠传输，即不管是否到达接收方，故不需要拥塞控制

优点：速度快，开销少
缺点：消息容易丢失（特别是网络较差时）

应用场景：要求通信速度较高
DNS 域名转换，FTP 文件传输，SNMP 网络管理，NFS 远程文件服务器

报文段格式：UDP 的报文段共 2 个字段：数据字段&首部字段
首部字段(8 字节，4 个字段)
伪首部：12 字节，计算检验和(不想下传送，也不想上递交)，实际不属于 UDP 首部
源端口：2 字节，源端口号，需要对方回信时使用，不需时设为 0
目的端口：2 字节，目的端口号，终点交付报文时需使用到
长度：2 字节，UDP 用户数据报的长度，最小值为 8(仅有首部)
检验和：2 字节，检测 UDP 用户数据报在传输中是否有错，若有错则丢弃

TCP UDP 协议的区别
特点：
TCP：面向连接，可靠，字节流
UDP：无连接，不可靠，数据报文段
性能：
TCP：传输效率慢，所需资源多
UDP：传输效率快，所需资源少
应用场景：
TCP：需要通信数据可靠(如文件传输，邮件传输)
UDP：要求通信速度高(如域名转换)
首部字节：
TCP：20-60
UDP：8 个字节(由 4 个字段组成)

HTTP 协议：
定义：即 HyperText Transfer Protocol，一种超文本传输协议，属于应用层
作用：规定了应用进程间的通行的准则
特点： 1. 传输效率高：1.无连接：交换 HTTP 报文前，不需要建立 HTTP 连接 2.无状态：数据传输过程中不保存任何历史&状态信息，该特性简化了服务器的设计，是服务器更容易 3.传输格式简单：请求时，只需传送请求方法&路径

    		2. 传输可靠性高：1.采用TCP作为运输层协议，交换报文时，需预先建立TCP连接

    		3. 其余：兼容性好：支持B/S，C/S模式
    				灵活性高：HTTP允许传输任意类型的数据对象

Nginx：nginx 是一个 WEB 服务器，反向代理服务器，缓存服务器。
为什么使用 nginx？ 1. 跨平台，配置简单，非阻塞，高并发连接：处理 2-3 万并发连接数，官方检测能支持 5 万并发。 2. 内存消耗小：开启 10 个 nginx 才占 150M 内存，nginx 处理静态资源好，消费内存少. 3. 内置的简单检查功能:如果一个服务器宕机,会做一个健康检查,再发送的请求就不会发送到宕机的服务器了,从新将请求提交给其他节点上. 4. 节省带宽：支持 gzip 压缩，可以添加浏览器本地缓存。 5. 稳定性高：宕机的概率非常小。 6. 接收用户请求是异步的
为什么 Nginx 性能这么高？
因为他的事件处理机制：异步非阻塞事件处理机制：运用了 epoll 模型，提供了一个队列，排队解决

GC 垃圾收集器：GC 收集算法是内存回收的方法论，垃圾收集器是内存回收的具体实现。

    Java虚拟机规范中对垃圾收集器应该如何实现并没有任何规定，因此不同的厂商、不同版本的虚拟机所提供的垃圾收集器都可能会有很大差别，并且一般都会提供参数供用户根据自己应用的特点和要求组合出各个年代所使用的收集器。
    Young Generation: Serial, ParNew, Parallel Scavenge
    Tenured Generation:CMS, Serial Old(MSC), Parallel Old
    G1

    基本概念：并发和并行
    		并行(Parallel):指多条垃圾收集器并行工作，但此时用户线程仍然处于等待装态
    		并发(Concurrent):指用户线程与垃圾收集线程同时执行（并不一定是并行的，可能会交替执行），用户程序在继续运行，而垃圾收集程序运行在另一个CPU上。

    		Minor GC：指发生在新生代的垃圾收集动作，因为Java对象大多都具备朝生熄灭的特性，所以Minor GC非常频繁，一般回收速度也比较快。

    		Old GC: 指发生在老年代的GC，出现了Major GC，经常会伴随至少一次Minor GC（并非绝对的，在Parallel Scavenge收集器的收集策略里就有直接进行Major GC的策略选择过程）。Major GC的速度一般比Minor GC慢10倍以上。

    		吞吐量：吞吐量就是CPU运行用户代码的时间与CPU总消耗时间的比值，即吞吐量=运行用户代码时间/(运行用户代码时间+垃圾收集时间)。如果虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。

    1）Serial收集器：是最基本的，发展历史最悠久的收集器，曾经（在JDK 1.3.1之前）是虚拟机新生代收集的唯一选择。
    特性：这个收集器是一个单线程的收集器，但它的“单线程”的意义并不仅仅说明它只会使用一个CPU或一条收集线程去完成垃圾收集工作，更重要的是在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束（Stop The World）。
    应用场景：Serial收集器是虚拟机运行在Client模式下的默认新生代收集器。
    优势：简单而高效（与其他收集器的单线程比），对于限定单个CPU的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。

    （2）ParNew收集器：参上
     特性：ParNew收集器其实就是Serial收集器的多线程版本，除了使用多条线程进行垃圾收集之外，其余行为包括Serial收集器可用的所有控制参数、收集算法、Stop The World、对象分配规则、回收策略等都与Serial收集器完全一样，在实现上，这两种收集器也共用了相当多的代码。

     应用场景：ParNew收集器是许多运行在Server模式下的虚拟机中首选的新生代收集器。

     很重要的原因是：除了Serial收集器外，目前只有它能与CMS收集器配合工作。在JDK 1.5时期，HotSpot推出了一款在强交互应用中几乎可认为有划时代意义的垃圾收集器——CMS收集器，这款收集器是HotSpot虚拟机中第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程同时工作。不幸的是，CMS作为老年代的收集器，却无法与JDK 1.4.0中已经存在的新生代收集器Parallel Scavenge配合工作，所以在JDK 1.5中使用CMS来收集老年代的时候，新生代只能选择ParNew或者Serial收集器中的一个。

     （3）Parallel Scavenge收集器：
      特性：Parallel Scavenge收集器是一个新生代收集器，它也是使用复制算法的收集器，又是并行的多线程收集器。

      应用场景：
      停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验，而高吞吐量则可以高效率地利用CPU时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。

      对比分析：
      Parallel Scavenge收集器 VS CMS等收集器：
      Parallel Scavenge收集器的特点是它的关注点与其他收集器不同，CMS等收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量（Throughput）。
      由于与吞吐量关系密切，Parallel Scavenge收集器也经常称为“吞吐量优先”收集器。

      Parallel Scavenge收集器 VS ParNew收集器：
      Parallel Scavenge收集器与ParNew收集器的一个重要区别是它具有自适应调节策略。

      GC自适应的调节策略：
      Parallel Scavenge收集器有一个参数-XX:+UseAdaptiveSizePolicy。当这个参数打开之后，就不需要手工指定新生代的大小、Eden与Survivor区的比例、晋升老年代对象年龄等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种调节方式称为GC自适应的调节策略（GC Ergonomics）。

      CMS收集器：
      特性：
    	CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用集中在互联网站或者B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。CMS收集器就非常符合这类应用的需求。
    	CMS收集器是基于“标记—清除”算法实现的，它的运作过程相对于前面几种收集器来说更复杂一些，整个过程分为4个步骤：

    	初始标记（CMS initial mark）
    	初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，需要“Stop The World”。

    	并发标记（CMS concurrent mark）
    	并发标记阶段就是进行GC Roots Tracing的过程。

    	重新标记（CMS remark）
    	重新标记阶段是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短，仍然需要“Stop The World”。

    	并发清除（CMS concurrent sweep）
    	并发清除阶段会清除对象。

    	由于整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作，所以，从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。

    	优点：
    	CMS是一款优秀的收集器，它的主要优点在名字上已经体现出来了：并发收集、低停顿。

    	缺点：
    	CMS收集器对CPU资源非常敏感，其实，面向并发设计的程序都对CPU资源比较敏感。在并发阶段，它虽然不会导致用户线程停顿，但是会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢，总吞吐量会降低。
    	CMS默认启动的回收线程数是（CPU数量+3）/ 4，也就是当CPU在4个以上时，并发回收时垃圾收集线程不少于25%的CPU资源，并且随着CPU数量的增加而下降。但是当CPU不足4个（譬如2个）时，CMS对用户程序的影响就可能变得很大。

    	CMS收集器无法处理浮动垃圾
    	CMS收集器无法处理浮动垃圾，可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。

    	由于CMS并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS无法在当次收集中处理掉它们，只好留待下一次GC时再清理掉。这一部分垃圾就称为“浮动垃圾”。也是由于在垃圾收集阶段用户线程还需要运行，那也就还需要预留有足够的内存空间给用户线程使用，因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间提供并发收集时的程序运作使用。要是CMS运行期间预留的内存无法满足程序需要，就会出现一次“Concurrent Mode Failure”失败，这时虚拟机将启动后备预案：临时启用Serial Old收集器来重新进行老年代的垃圾收集，这样停顿时间就很长了。

    	CMS收集器会产生大量空间碎片
    	CMS是一款基于“标记—清除”算法实现的收集器，这意味着收集结束时会有大量空间碎片产生。空间碎片过多时，将会给大对象分配带来很大麻烦，往往会出现老年代还有很大空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前触发一次Full GC。

    	（7）G1收集器：
    	特性：
    	G1（Garbage-First）是一款面向服务端应用的垃圾收集器。HotSpot开发团队赋予它的使命是未来可以替换掉JDK 1.5中发布的CMS收集器。与其他GC收集器相比，G1具备如下特点。

    	并行与并发
    	G1能充分利用多CPU、多核环境下的硬件优势，使用多个CPU来缩短Stop-The-World停顿的时间，部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让Java程序继续执行。

    	分代收集
    	与其他收集器一样，分代概念在G1中依然得以保留。虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但它能够采用不同的方式去处理新创建的对象和已经存活了一段时间、熬过多次GC的旧对象以获取更好的收集效果。

    	空间整合
    	与CMS的“标记—清理”算法不同，G1从整体来看是基于“标记—整理”算法实现的收集器，从局部（两个Region之间）上来看是基于“复制”算法实现的，但无论如何，这两种算法都意味着G1运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。

    	可预测的停顿
    	这是G1相对于CMS的另一大优势，降低停顿时间是G1和CMS共同的关注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒。

    	在G1之前的其他收集器进行收集的范围都是整个新生代或者老年代，而G1不再是这样。使用G1收集器时，Java堆的内存布局就与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分Region（不需要连续）的集合。

    	G1收集器之所以能建立可预测的停顿时间模型，是因为它可以有计划地避免在整个Java堆中进行全区域的垃圾收集。G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region（这也就是Garbage-First名称的来由）。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。

    	执行过程：
    	G1收集器的运作大致可划分为以下几个步骤：

    初始标记（Initial Marking）
    初始标记阶段仅仅只是标记一下GC Roots能直接关联到的对象，并且修改TAMS（Next Top at Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可用的Region中创建新对象，这阶段需要停顿线程，但耗时很短。

    并发标记（Concurrent Marking）
    并发标记阶段是从GC Root开始对堆中对象进行可达性分析，找出存活的对象，这阶段耗时较长，但可与用户程序并发执行。

    最终标记（Final Marking）
    最终标记阶段是为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程Remembered Set Logs里面，最终标记阶段需要把Remembered Set Logs的数据合并到Remembered Set中，这阶段需要停顿线程，但是可并行执行。

    筛选回收（Live Data Counting and Evacuation）
    筛选回收阶段首先对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿时间来制定回收计划，这个阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控制的，而且停顿用户线程将大幅提高收集效率。

MyBatis 常见问题：
1、什么是 Mybatis？

    （1）Mybatis是一个半ORM（对象关系映射）框架，它内部封装了JDBC，开发时只需要关注SQL语句本身，不需要花费精力去处理加载驱动、创建连接、创建statement等繁杂的过程。程序员直接编写原生态sql，可以严格控制sql执行性能，灵活度高。

    （2）MyBatis 可以使用 XML 或注解来配置和映射原生信息，将 POJO映射成数据库中的记录，避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。

    （3）通过xml 文件或注解的方式将要执行的各种 statement 配置起来，并通过java对象和 statement中sql的动态参数进行映射生成最终执行的sql语句，最后由mybatis框架执行sql并将结果映射为java对象并返回。（从执行sql到返回result的过程）。

    2、Mybaits的优点：

    （1）基于SQL语句编程，相当灵活，不会对应用程序或者数据库的现有设计造成任何影响，SQL写在XML里，解除sql与程序代码的耦合，便于统一管理；提供XML标签，支持编写动态SQL语句，并可重用。

    （2）与JDBC相比，减少了50%以上的代码量，消除了JDBC大量冗余的代码，不需要手动开关连接；

    （3）很好的与各种数据库兼容（因为MyBatis使用JDBC来连接数据库，所以只要JDBC支持的数据库MyBatis都支持）。

    （4）能够与Spring很好的集成；

    （5）提供映射标签，支持对象与数据库的ORM字段关系映射；提供对象关系映射标签，支持对象关系组件维护。

    3、MyBatis框架的缺点：

    （1）SQL语句的编写工作量较大，尤其当字段多、关联表多时，对开发人员编写SQL语句的功底有一定要求。

    （2）SQL语句依赖于数据库，导致数据库移植性差，不能随意更换数据库。

    4、MyBatis框架适用场合：

    （1）MyBatis专注于SQL本身，是一个足够灵活的DAO层解决方案。

    （2）对性能的要求很高，或者需求变化较多的项目，如互联网项目，MyBatis将是不错的选择。

5、MyBatis 与 Hibernate 有哪些不同？

（1）Mybatis 和 hibernate 不同，它不完全是一个 ORM 框架，因为 MyBatis 需要程序员自己编写 Sql 语句。

（2）Mybatis 直接编写原生态 sql，可以严格控制 sql 执行性能，灵活度高，非常适合对关系数据模型要求不高的软件开发，因为这类软件需求变化频繁，一但需求变化要求迅速输出成果。但是灵活的前提是 mybatis 无法做到数据库无关性，如果需要实现支持多种数据库的软件，则需要自定义多套 sql 映射文件，工作量大。

（3）Hibernate 对象/关系映射能力强，数据库无关性好，对于关系模型要求高的软件，如果用 hibernate 开发可以节省很多代码，提高效率。

6、#{}和\${}的区别是什么？

#{}是预编译处理，\${}是字符串替换。

Mybatis 在处理#{}时，会将 sql 中的#{}替换为?号，调用 PreparedStatement 的 set 方法来赋值；

Mybatis 在处理${}时，就是把${}替换成变量的值。

使用#{}可以有效的防止 SQL 注入，提高系统安全性。

Java 中的反射机制和动态代理 1. 反射概述：反射机制指的是 Java 在运行时候有一种自观的能力，能够了解自身的情况为下一步做准备，其想表达的意思就是：在运行状态中，对于任意一个类，都能够获取到这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性(包括私有的方法和属性)，这种动态获取的信息以及动态调用对象的方法的功能就称为 java 语言的反射机制。通俗点讲，通过反射，该类对我们来说是完全透明的，想要获取任何东西都可以，这是一种动态获取类的信息以及动态调用对象方法的能力。

想要使用反射机制，就必须要先获取到该类的字节码文件对象(.class)，这种动态获取的信息以及动态调用对象的方法的功能就称为 java 语言的反射机制。通俗点讲，通过反射，该类对我们来说是完全透明的，想要获取任何东西都可以，这是一种动态获取类的信息以及动态调用对象方法的能力。以及动态调用对象的方法的功能就称为 java 语言的反射机制。通俗点讲，通过反射，该类对我们来说是完全透明的，想要获取任何东西都可以，这是一种动态获取类的信息以及动态调用对象方法的能力。通过该类的字节码对象，就能够通过该类中的方法获取到我们想要的所有信息(方法，属性，类名，父类名，实现的所有接口等等)，每一个类对应着一个字节码文件也就对应着一个 Class 类型的对象，也就是字节码文件对象。

Java 提供的反射机制，依赖于我们下面要讲到的 Class 类和 java.lang.reflect 类库。我们下面要学习使用的主要类有：①Class 表示类或者接口；②java.lang.reflect.Field 表示类中的成员变量；③java.lang.reflect.Method 表示类中的方法；④java.lang.reflect.Constructor 表示类的构造方法；⑤Array 提供动态数组的创建和访问数组的静态方法。

Cookie
HTTP 协议是无状态的，主要是为了让 HTTp 协议尽可能的简单，使得它能够处理大量事务。HTTP/1.1 引入了 Cookie 来保存状态信息。

    	Cookie是服务器发送到用户浏览器并保存在本地的一下块数据，它会在浏览器之后向同一服务器再次发送请求时被携带上，用于告知服务端两个请求是否老子同一个服务器。因为之后的每次请求都会带上Cookie数据，因此回带来额外的性能开销（尤其在移动环境下）。

    	Cookie曾一度用于客户端数据的存储，因为当时并没有其他合适的存储办法而作为唯一的存储手段，但现在随着现代浏览器开始支持各种各样的存储方式，Cookie渐渐被淘汰。新的浏览器API已经允许开发者直接将数据存储在本地，如使用WebStorage API(本地存储和绘画存储)或IndexedDB。

    	1.用途
    		 会话状态管理（如用户登陆状态，购物车，游戏分数或其它需要记录的信息）
    		 个性化设置（如用户自定义设置，主题）
    		 浏览器行为跟踪（如跟踪分析用户行为等）

    	2.创建过程
    		服务器发送的响应报文包含Set-Cookie首部字段，客户端得到响应报文后把Cookie内容保存到浏览器中。
    		客户端之后对同一个服务器发送求情时，会从浏览器中取出Cookie信息并通过Cookie信息并通过首部字段发送给服务器。

    	3.分类
    		会话期Cookie：浏览器关闭之后会自动删除，也就是说它仅会在会话期内有效
    		持久性Cookie：指定过期时间（Expires）或有效期（max-age）之后就成为了持久性Cookie。

    	4.作用域
    		Domain标识指定了哪些主机可以接受Cookie。如果不指定，默认当前文档的主机（不包含子域名）。如果指定了Domain，则一般包含子域名。例如，如果设置了Domain=mozilla.rog，则Cookie也包含在子域名中（如developer.mozilla.org）。
    		Path标识指定了哪些路径可以接受Cookie（该URL路径必须存在请求URL中）。以字符 %x2F("/")作为路径分隔符，子路径也会被匹配。例如，设置Path=/docs，则以下地址都会匹配：
    		/docs
    		/docs/Web/
    		/docs/Web/HTTP

    	5.JavaScript
    		浏览器通过document.cookie属性可创建新的Cookie，也可通过该属性访问非HttpOnly标记的Cookie。

    	6.HttpOnly
    	标记为HttpOnly的Cookie不能被Javascript脚本调用。跨站脚本攻击(XSS)常常使用Javascript的document.cookie API窃取用户的Cookie信息，因此使用HttpOnly标记可以在一定程度上避免XSS攻击。

    	7.Secure
    		标记为Secure的Cookie只能通过HTTPS协议加密过的请求发送给服务端。但即便设置了Secure表姐，敏感信息也不应该通过Cookie传输，因为Cookie有其固有的不安全性，Secure标记也无法提供确实的安全保障。

    	8.Session
    		除了可以将用户信息通过Cookie存储在用户浏览器中，也可以利用Session存储在服务器端，存储在服务器端的信息更加安全。Session可以存储在服务器上的文件、数据库或者内存中。也可以将Session存储在Redis这种内存数据库中，效率会更高。
    		使用Session维护用户状态的过程如下：
    			1）用户进行登录时，用户提交包含用户名和密码的表单，放在HTTP请求报文中；
    			2）服务器验证该用户名和密码，如果正确则把用户Redis中，它在Redis中的Key称为SessionID；
    			3）服务器返回的响应报文的Set-Cookie首部字段包含了这个Session ID，客户端收到响应报文之后将该Cookie值存入浏览器中；
    			4）客户端之后对同一个服务器进行请求时会包含Cookie值，服务器收到之后提取出Session ID，从Redis中取出用户信息，继续之前的业务操作。

    	应该注意Session ID的安全性问题，不能让他被恶意攻击者轻易获取，那么就不能产生一个容易被猜到的Session ID值。此外，还需要经常重新生成Session ID。在对安全性要求极高的场景下，例如转账等操作，除了使用Session管理用户状态之外，还需要对用户进行重新验证，比如重新输入密码，或者使用短信验证码等方式。

    	9.浏览器禁用Cookie
    		此时无法使用Cookie来保存用户信息，只能使用Session。除此之外，不能再将Session ID存放在Cookie中，而是使用URL重写技术，将SessionID作为URL的参数进行传递。

    	10.Cookie与Session选择
    		1）Cookie只能存储ASCII码字符串，而Session则可以存储任何类型的数据，因此在考虑数据复杂性时首选Session。
    		2）Cookie存储在浏览器中，容易被恶意查看。如果非要将一些隐私数据存在Cookie中，可以将Cookie值进行加密，然后在服务器端进行解密；
    		3）对于大型网站来说，如果用户所有的信息都存储在Session中，那么开销是非常大的，因此不建议将所有用户信息都存储在Session中。
